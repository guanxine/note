## 三个核心问题
1. 分工(性能): 高效的拆解任务并分配给线程. 如何分工:Executor,Fork/Join,Future, 生产者-消费者, Thread-Pre-Message, Worker Thread 
2. 同步(性能): 线程之间如何协作。分工之后就是具体执行了，执行过程中，任务之间有依赖。一个任务结束后，如何通知后续的任务开始执行。可以描述为：当某个条件不满足时线程需要等待，当某个条件满足时，线程需要被唤醒执行。解决协作的核心问题是：管程
3. 互斥(安全): 同一时刻只允许一个线程访问共享资源. 当不同的线程访问一个共享变量时，结果是不确定的。不确定的源头是可见性问题，有序性问题，原子性问题。为了解决这三个问题，Java 引入了内存模型，提供了一些列规则，利用这些规则可以解决可见性，有序性。但是不足以完全解决线程安全问题。解决线程安全的核心方案：互斥。方法：
锁，无锁，不共享变量(ThreadLocal)或变量只读(final)
例子
生产者消费者:大厨和服务员，大厨就是生产者，负责做菜，放到出菜口，而服务员就是消费者。把做好的菜端过来。优点，生产者一个一个的生产数据，而消费者可以批处理。提高了性能

## 并发bug
1. 缓存导致可见性：一个线程对共享变量的修改，另一个线程能够立刻看到。我们称为可见性。当多个线程在一个cpu上执行时，操作同一个cpu缓存没有可见性问题。当多个线程不在不同的cpu上执行时，这些线程操作的是不同的cpu缓存。这时cpu缓存和内存的数据一致性就没那么容易解决。
2. 线程切换导致原子性：操作系统允许某个进程执行一小段时间，例如50ms(时间片),过了这个时间，操作系统重新选择一个进程来执行。一个条语句(count+=1)往往需要多条cpu指令完成。我们把一个或这多个操作在cpu执行过程中不被中断的特性成为原子性。cpu能保证原子操作是指令级别的，而不是高级语言的操作符。因此我们需要在高级语言层面保证操作的原子性。
3. 编译优化带来的有序性
```
A a = new A();
顺序
1. 分配一块内存M
2. 在内存 M 上初始化 A 对象
3. 然后把 M 的地址赋值给 a
指令重排后
1. 分配一块内存M
2. 将 M 的地址赋值给 a 
3. 最后在内存 M 上初始化 A 对象
```

## java 内存模型(可见性，有序性)
导致可见性的原因是缓存，导致有序性的原因是编译优化
解决办法：按需禁用缓存和编译优化
Java 的内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法：volatile（禁用cpu缓存，增强）, synchronized,final. 以及6项 Happens-Before 规则

Happens-before（语义 可见性 A happens-before B 意味着 A 事件对 B 事件来说总是可见的， 无论 A 和 B 是否发生在同一个线程里）
前一个操作的结果对后续操作是可见的。编译器优化后一定遵循 Happens-before 原则。
1. 程序顺序性
2. volatile 规则， 对一个 volatile 变量的写操作， Happens-before 于后续对这个 volatile 变量的读操作。对于一个 volatile 变量的写操作相对于后续对这个volatile 变量的读操作可见
3. 传递性：A happens-before B 且 B happens-before C. 那么 A happens-before C.
4. 管程中锁的规则：对一个锁的解锁 Happens-before 于后续对这个锁的加锁。管程是一种通用的同步原语。在 Java 中就是 synchronized.
5. 线程 start() 规则：主线程 A 启动子线程 B 后, 子线程 B 能够看到主线程在启动子线程 B 前的操作。
6. 线程 join() 规则：主线程 A 等待子线程 B 完成（主线程 A 调用子线程 B 的 join() 方法实现），当子线程 B 完成后，主线程能够看到子线程的操作（共享变量）

## 原子性：线程切换
原子性的源头：线程切换(操作系统进行线程切换是依赖 cpu 中断的)
在32位 cpu 上 long（64位）的写操作被拆为两次写操作（高位32位和低位32位）， 在多核场景下，有可能两个线程在同时运行。可能会出现两个线程同时写高位的情况。
互斥：同一时刻只有一个线程执行
解决原子性问题：要保证中间状态对外不可见

1. 简易锁模型： 加锁->临界区->解锁
把需要互斥执行的代码成为临界区
锁的是什么？保护的是什么？-> 用自家的锁保护自家的资源

2. 改进锁模型：创建保护资源R的锁（LR）-> 加锁操作：lock(LR) -> 临界区：一段代码(受保护资源R) -> 解锁操作：unlock(LR)
3. synchronized： 不能改变操作系统线程切换的特点，只是其他线程要访问这个资源时，发现锁还未释放。所以只能在外面等。
修饰静态方法：锁定的是当前 class 对象
修饰非静态方法：锁定的是当前实例对象 this， 不能用可变对象做锁

4. 锁和受保护资源的关系
受保护资源和锁之间的关联关系是 N:1 的关系。和现实不同，不能用多把锁来保护同一个资源。可以用一把锁保护多个资源。

## 多个资源
1. 多个资源没有关联关系
2. 多个资源有关联关系

## 死锁（细粒度）
下面四个条件都发生才会出现死锁
1. 互斥: 共享资源 X 和 Y 只能被一个线程占用。
2. 占有等待: 线程 T1 已经获取资源 X， 在等待共享资源 Y 的时候，不释放共享资源X
3. 不可抢占: 其他线程不能抢占线程T1占有的资源
4. 循环等待: 线程 T1 等待线程 T2 占用资源，线程 T2 等待 T1 占用的资源

破坏其中一个就可避免死锁。
1. 互斥没办法破坏，锁就是互斥
2. 占用等待：一次性申请所有资源。
3. 不可占用：占用部分资源的线程，进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。等待-通知, wait() 释放了锁
4. 循环等待：按序申请资源。先申请资源序号小的，再申请资源序号大的。

## 等待通知
当线程要求的条件不满足时，线程阻塞，进入等待状态。当线程要求的条件满足时，通知等待的线程重新执行。
synchronized 配合 wait(),notify(),notifyAll() 这几个方法在 synchronized 内部调用 
```
 while(条件不满足) { wait(); }

```

## 安全性问题
数据竞争：多个线程同时读写同一个数据。
竞态条件：程序的执行结果依赖线程执行的顺序。多线程中线程的执行顺序不一样，如果存在竞态条件，则执行结果不确定。而执行结果不确定这可是个大bug. 条件不是显示的，
## 活跃性问题（死锁）
某个操作无法执行下去
1. 活锁：没有发生阻塞，但仍然执行不下去。让两个线程随机等待不同的时间后切换。Raft 分布式一致性算法用到了它。
2. 饥饿：线程无法访问所需要的资源。
  + 保证资源充足
  + 公平分配资源： 适用场景更多，公平锁，先来后到，线程的等待是有顺序的。排在队列前面的线程优先获取资源。
  + 避免持有锁的线程长时间执行

## 性能问题
“锁” 过度使用可能导致串行化
1. 无锁的算法和数据结构：线程本地存储(Thread Local Storage, TLS), 写入时复制(copy-on-write),乐观锁等， Java 原子类无锁结构，Disruptor 无锁队列
2. 减少锁持有时间，互斥锁的本质将并行的程序串行化。
  + 使用细粒度锁：ConcurrentHashMap，采用了分段锁的技术
  + 读写锁: 读是无锁的，只有写的时候才会互斥。
性能方面给有3个指标
1. 吞吐量: 单位时间内能处理的请求数量，吞吐量越高，性能越好
2. 延迟: 发出请求到收到响应的时间，延迟越小，性能越好
3. 并发量:能同时处理的请求数量，一般来说并发量增加，延迟也会增加。所以延迟是基于并发量来说的。比如并发1000，延迟是50毫秒 

## 管程
管理共享变量以及对共享变量的操作过程，让他们支持并发。
Java: 管理类成员变量和成员方法。让这个类线程安全。

并发两大核心问题
1. 互斥：同一时刻只允许一个线程访问共享资源
2. 同步：线程之间如何通信，协作

MESA 模型
每个条件变量都对应一个等待队列。
1. 入队，队列满，等到队列不满（notFull.await()）, 入队后，队列就不空了，通知（队列不空）条件变量:可通知出队。
2. 出队，队列空，等待队列不空 (notEmpty.await())，出队后，队列就不满了，通知（队列不满）条件变量：可通知入队。

## 生命周期
通用线程的生命周期：
1. 初始状态
2. 可运行状态
3. 运行状态
4. 休眠状态
5. 终止状态

Java 中线程生命周期
1. NEW
2. RUNNABLE
  3. BLOCKED, 4. WAITING, 5. TIMED_WAITING: 细分了休眠状态，只要 JAVA 处于这三种状态之一，那么这个线程永远没有 CPU 使用权。
6. TERMINATED

RUNNABLE 和 BLOCKED 相互转换： synchronized 修饰的方法或者代码块
RUNNABLE 和 WAITING 相互转换：Object.wait()/ threadA.join()/
RUNNABLE 和 TIMED_WAITING 相互转换：Thread.sleep(time)/Object.wait(time)


stop 和 interrupt 区别

stop 杀死线程，如果有 ReentrantLock 锁，不会 unlock() 释放锁。
interrupt 仅仅通知线程，线程有机会执行一些后续操作，同时也可以无视这个通知。
两种方式收到通知
1. 异常: 调用 ta.interrupt()（中断标志）, 当 ta 处于 WAITING,TIMED_WAITING 状态时，会使线程返回到RUNNABLE状态，并抛出 InterruptedException， 并且中断标志会被清除了，此时 ta.isInterrupted 返回 false.
2. 主动检测: 当调用了 ta.interrupt()，当 ta 处于 RUNNABLE 并且没有阻塞在 IO 操作上，可通过 ta.isInterrupted 方法检测自己是不是被中断了

## 创建多少线程合适
首先分析两个问题
1. 为什么使用多线程
2. 多线程的应用场景

cpu + IO
1. cpu 密集型计算场景，线程数=核数，工程上一般设置线程数=核数+1，太多导致频繁的线程切换，当线程因为其他原因导致阻塞时，额外的线程可以顶上，从而保证 cpu 的利用率。
2. io 密集型计算场景，最佳线程数=[1 + (IO/CPU) ] * 核心数

## 为什么局部变量是线程安全的。
方法和里面的局部变量在栈中，一个变量如果想好跨越方法的边界，就必须在堆中创建。
每个线程都有自己独立的调用栈，不会共享变量。

### 线程封闭
尽在单线程内访问数据
例子：数据库连接池通过线程封闭技术，保证 conneciton 一旦被一个线程获取之后，在这个线程关闭 Connection 之前的这段时间里，不会再分配给其他线程，从而保证了 Connection 不会有并发问题。

## 用面向对象思想写好并发
核心问题：解决多线程共同访问共享变量的问题。
1. 将共享变量作为对象的属性封装在内部，对所有公共方法制定并发访问策略。
2. 识别共享变量间的约束条件：约束条件，决定了并发访问策略
   当看到代码里出现 if 语句的时候，就应该立刻意识到可能存在竞态条件。
3. 并发访问策略
  + 避免共享：线程本地存储和每个任务分配独立线程
  + 不变模式：java 很少用
  + 管程和其他同步工具：读写锁，并发容器等同步工具。

宏观原则
1. 使用成熟工具类
2. 迫不得已使用低级同步原语：synchronized,Lock
3. 避免过早优化：并发程序先保证正确，出现性能瓶颈后再优化


## Lock 和 Condition ： 隐藏管程
1. Lock: 解决互斥
2. Condition: 解决同步

 为什么要重复造轮子? 
 synchroinzed 获取不到锁会进入阻塞状态，发生死锁。
 原有的 synchroinzed 没办法破坏“不可抢占”这个条件从而解决死锁问题。
 1. 能够响应中断。
 2. 支持超时：一段时间内没有获取锁，不进入阻塞状态，而是返回错误，有机会释放锁
 3. 非阻塞获取锁：获取锁失败，并不进入阻塞状态，而是直接返回。

 Lock 可见性
 利用了 volatile 相关的 happens-before 原则。
 ReentrantLock 内部持有一个 volatile 的成员变量 state. 
 获取锁，和解锁都会读写 state 值。
 1. 顺序性：对于线程1，共享变量 hb 于 解锁
 2. volatile: 线程1 解锁 hb 于线程2加锁
 3. 传递性： 共享变量 hb 于线程2

ReentrantLock
可重入锁： ReentrantLock: 线程可以重复获取同一把锁。
可重入函数：多个线程可以同时调用函数。
公平锁: 唤醒策略, 谁等待的时间长，唤醒谁。公平
非公平锁：不提供保障，很可能等待时间短的线程反而被先唤醒。

锁最佳实践
1. 只在更新对象的成员变量时加锁
2. 只在访问可变的成员变量时加锁
3. 不再调用其他对象的方法时加锁：其他对象的方法也许有 sleep, 有耗时的 IO, 甚至加锁，可能会导致死锁。
4. 减少锁的持有时间
5. 减小锁的粒度

Condition
实现了管程模型里面的条件变量

例子：利用两个条件变量实现阻塞队列。
Lock & Condition: await(), signal(), signalAll()
synchronized: wait(), notify(), notifyAll()

### Dubbo 中如何使用 Lock & Condition

同步与异步
简单来说，调用放是否需要等待结果，如果需要等待结果就是同步，如果不需要等待结果就是异步。
同步，是 java 代码默认的处理方式。如果想要支持异步，两种方式
1. 调用方创建一个子线程，在子线程中执行方法调用，这种调用我们称为异步调用
2. 方法实现的时候，创建一个新的线程执行主要逻辑，主线程直接 return, 这种方法一般位异步方法。

当 RPC 返回结果之前，阻塞调用线程，让调用线程等待。
当 RPC 返回结果后，唤醒调用线程，让调用线程重新执行


## Semaphore 信号量（和管程相比）
信号量模型：一个计数器（可用资源的数量），一个等待队列，三个方法：init(),down(),up()
PV 原语, 两个操作都是原子操作（意思只有一个线程操作信号量）
P原语(down/acquire): 阻塞原语，负责把当前进程由运行状态转换为阻塞状态。操作为，申请一个空闲资源（信号量-1），若成功，则退出，若失败，则该进程被阻塞。
V原语(up/release)：唤醒原语, 负责把一个被阻塞的进程唤醒。操作为，释放一个被占用的资源（信号量+1），发现有被阻塞的进程，则选择一个唤醒。

1. 实现互斥锁：new Semaphore(1)
2. 允许多个线程访问一个临界区：各种池化资源，比如连接池，对象池，线程池，数据库链接池。同一时刻，一定是允许多个线程同时使用线程池，当然每个链接在被释放前，是不允许其他线程使用的。

对象池：可以用 List 保存实例对象。关键是限流，指的是不允许多于N个线程同时进入临界区。用信号量解决。
需要注意的是多个线程进入了临界区，注意临界区线程安全问题。

## ReadWriteLock（完备的缓存）
管程(Lock & Condition)和信号量(Semaphore) 这两个同步原语，理论上用这两个的任何一个都可以解决所有的并发问题。
为啥还有很多其他的工具类？分场景优化性能，提升易用性。
并发场景：读多写少
为了优化性能，我们经常使用缓存，例如缓存元数据，缓存基础数据。缓存之所以提升性能，一个重要的条件就是缓存的数据一定是读多（使用的地方多）写少（基本不会发生变化）。

针对读多写少：ReadWriteLock
1. 允许多个线程同时读共享变量
2. 只允许一个变量写共享变量
3. 如果一个写线程正在执行写操作，禁止读线程读共享变量。

写锁和读锁，写锁和写锁是互斥的。

1. 获取写锁的前提是，读锁和写锁没有被其他线程占用
2. 获取读锁的前提是，写锁没有被其他线程占用

读锁->写锁

锁降级：在不释放写锁的前提下，允许获取读锁
锁升级：在不释放读锁的前提下，不允许获取写锁

缓存
1. 初始化问题
2. 保证缓存数据和源头数据一致性.
    + 解决数据同步一个最简单的方案就是：超时机制。加载的数据是有时效的。当缓存的数据超时失效，该数据失效，而访问缓存中失效数据，会触发缓存重新从源头把数据加载进缓存。
    + 源头发生改变，推送给缓存

## StampedLock (java 1.8)
性能比读写锁好
1. 写锁
2. 悲观读锁
3. 乐观读：支持多个线程同时读，是允许一个线程获取写锁，也就是说不是所有的写操作都被阻塞。乐观读这个操作是无锁的。所以相对于 ReadWriteLock 的读锁，乐观读的性能更好。

数据库的乐观锁和 StampedLock 乐观读差不多
数据库中的乐观锁
1. 查询 version
2. 更新时利用 version 做验证： update table set version = version+1 where id = xxx and version=xx;


## 如何让多线程保持步调一致
1. CountDownLatch: 一个线程等待多个线程的场景，不能循环利用，一旦计数器减为0，再有线程调用 await(), 会直接通过
2. CyclicBarrier: 一组线程之间的相互等待，可以循环利用，具备自动重置，一旦计数器减到0会自动重置到你设置的初始值，可以设置回调函数。计数器=0时回调执行。

## 并发容器
Java 容器分类
1. List
2. Map
3. Set
5. Queue

如何将线程不安全的容器,组合容器 变成线程安全的。 
Collections.synchronizedXxx().
组合操作需要注意竞态条件，即便每个操作能保证原子性，也并不能保证组合操作的原子性。

容器领域有一个容易被忽视的坑，用迭代器遍历容器。

同步容器：Vector,Stack 和 Hashtable 基于 synchronized 实现,对这三个容器遍历同样需要加锁保证互斥。

同步容器：Collections.synchronizedXxx() 包装实现，Vector,Stack 和 Hashtable

### 并发容器
java 1.5 之前所谓线程安全的容器都是同步容器。都用 synchronized 来保证互斥，串行度太高，
性能差。在 1.5 和 之后提供了性能更高的容器。我们一般称为并发容器。
1. List: CopyOnWriteArrayList. 写时将共享变量复制一份出来。好处读操作无锁。
  + 遍历操作基于原 array 执行，写操作复制一份，基于新的 array 进行
  + 场景：写操作非常少，能容忍读写短暂的不一致
  + 迭代器只读（遍历的仅是快照）。
2. Map: ConcurrentHashMap(key 无序), ConcurrentSkipListMap（key 有序）， ConcurrentSkipListMap 并发性能更高。
3. Set: CopyOnWriteArraySet 和 ConcurrentSkipListSet
4. Queue: 并发容器里最复杂的
  + 阻塞(Blocking)与非阻塞: 阻塞当队列满时，入队操作阻塞。当队列空时，出队操作阻塞
  + 单端(Queue)与双端(Deque)

  使用队列时注意是否支持有界，实际工作中一般不建议使用无界队列。数量大后很容易 OOM。


## 原子类：无锁
原子类：硬件支持。 CPU 为了解决并发问题，提供了 CAS 指令。
指令包含3个参数： 共享变量内存地址A,用于比较的值B,共享变量的新值C. 只有当内存地址A的值等于B时，才能将内存中地址A处的值更新为新值C.
作为一条 CPU 指令，CAS 指令本身是能够保证原子性的。

使用 CAS 解决并发问题，一般都伴随着自旋，其实就是循环尝试。

## Executor与线程池
创建一个线程：需要调用操作系统内核的 API, 然后操作系统要为线程分配一系列的资源。所以线程是个重量级的对象，应该避免频繁的创建和销毁。
目前业界线程池设计，普遍都是生产者-消费者模式。线程池的使用方是生产者（创建任务提交给线程池中的队列），线程池本身是消费者（线程池中的线程消费队列中的任务）。

Java 中的线程池：ThreadPoolExecutor

```
ThreadPoolExecutor(
  int corePoolSize, // 线程池中有的最小线程数。
  int maximumPoolSize, // 线程池创建的最大线程数。任务比较多是，增加线程，并不是无限制的增加。最多到 maximumPoolSize, 任务少时，减少线程，减少到 corePoolSize 为止。
  long keepAliveTime, // 
  TimeUnit unit, // keepAliveTime & unit 定义一段时间，如果一个线程空闲了一段时间这么久，而且线程池中线程池数大于 corePoolSize, 这个空闲线程要被回收。
  BlockingQueue<Runnable> workQueue, // 工作队列，生产者-消费者
  ThreadFactory threadFactory, // 如何创建线程，例如给线程指定一个有意义的名字。
  RejectedExecutionHandler handler// 自定义任务的拒绝策略，如果线程池中所有的线程都在忙碌，并且工作队列也满了（工作队列是有界队列），那么提交任务，就会被拒绝接受。有4中策略，默认抛异常
  ) 
```
注意：
1. 构造函数复杂，有 Executors 静态工厂类来快速创建线程。规范都不建议使用。原因是：Executors 提供的默认方法，默认使用都是无界 LinkedBlockingQueue 高负载下，无界队列很容易 OOM, 而 OOM 会导致所有请求无法处理。强烈建议所有队列使用有界队列。
2. 有界队列，当任务过多时，会执行拒绝策略，默认抛出一个运行时异常，建议自定义拒绝策略 + 降级策略配合使用（将任务信息保存数据库，mq,redis，本地文件）
3. 线程池异常处理，通过 ThreadPoolExecutor 对象的 execute 提交任务时，如果任务执行过程中出现运行时异常，会导致执行任务线程终止，却得不到任何通知，误以为任务执行正常。虽然线程池提供了很多异常处理方法，最稳妥还是和简单的方案还是捕获所有异常，按需处理。
```
try {
  // 业务处理
}
catch(RuntimeException x) {
  // 按需处理
}
catch(Throwable x) {
  // 按需处理
}
```

## Future 获取任务执行结果
使用 Future 可以很容易获取异步任务的执行结果。Future 可以类比为现实世界里的提货单。利用多线程可以快速将一些串行化的任务并行化。
如果任务之间有依赖，比如当前任务依赖前一个任务的执行结果。这种问题基本上都可以用，Future 类解决。

简单的并行任务可以通过：线程池 +Future

## CompletableFuture(1.8)
异步编程
异步化，是并行方案得以实现的基础。
异步编程大大的优化了性能。

任务之间有聚合关系，无论是 AND 聚合还是 OR 聚合都可以通过 CompletableFuture 解决。


## CompletionService 
批量执行异步任务
内部维护了一个阻塞队列，当任务执行结束，就把任务的执行结果（Future）加入到阻塞队列中

解决批量的并行任务。

## Fork/Join
并发编程：分工，协作和互斥。
关注任务，已经从并发编程的细节中跳了出来，类比的往往是现实世界里的分工（线程池，Future,CompletableFuture,CompletionService）

任务模型
1. 简单并行
2. 聚合
3. 批量并行
4. 分治：把一个复杂的问题分解成多个相似的子问题，知道子问题可以直接求解。对问题的分治，也就是对任务的分治。

Fork: 对应的是分支任务模型里的任务分解。
Join: 对应的是结果的合并
1. 分治任务线程池：ForkJoinPool
2. 分治任务：ForkJoinTask
这两部分的关系类似于 ThreadPoolExecutor 和 Runnable 的关系，可以理解为提交任务到线程池，不过分治任务有自己独特的类型 ForkJoinTask



## Immutability 模式
如何利用不变性解决并发问题

快速实现具有不变性的类：将一个类所有的属性都设置成 final, 并且只允许存在只读的方法。这个类基本就具备不可变性了。
如果需要提供类似修改的功能，怎么办？创建一个新的不可变对象（String, Long, Integer,Double 等基本包装类，都是不可变类）

创建类过多？
利用享元模式(Flyweight Pattern)避免创建重复对象。
本质是一个对象池，创建前先看看对象池中是不是存在，如果已经存在，就利用对象池里的对象，如果不存在，就创建一个新对象，并且把新创建的对象放进对象池中。

模式需要注意两点
1. 对象的所有属性都是 final 的，并不能保证不可变性（如果属性的类型是一个普通对象，这个普通对象里的属性是可以被修改的。）
2. 不可变对象需要正确的发布（可见性->volatile，原子性->原子类）

## Copy-on-Write模式（COW）
String,Long等基本包装类都是基于 COW 实现的。缺点，每次修改都复制一个新对象出来，消耗内存。
写时复制
CopyOnWriteArrayList，CopyOnWriteArraySet 复制的是整个数组，经常被修改的数组本身非常的大，不建议使用
lock & volidate (lock 写，volidate 读副本)

1. Copy-on-Write 可以做到按需复制
避免共享，若共享，保证共享的是线程安全的。

## 线程本地模式：避免共享
ThreadLocal

Thread -> ThreadLocalMap<ThreadLocal<WeakReference>,Value>

ThreadLocal 内存泄漏
线程池中线程存活时间太长，往往和程序生命周期一样。
因为 Thread 持有的 ThreadLocalMap 一直都不会被回收。弱引用ThreadLocal会被回收，但是 value 不会被回收。
需要手动释放资源 remove                    

避免共享有两个方案：
1. 将这个工具类作为局部变量使用。缺点： 高并发场景下会频繁的创建对象。
2. 线程本地存储方案

创建的对象：threadlocal=线程数，局部变量=调用量

## Guarded Suspension模式
等待唤醒机制
多线程版本的 if 模式， 会等待条件。
##  Balking模式
如果不适合或者没必要执行这个操作，就停止处理，直接返回
再谈线程安全的单例模式

## Thread-Per-Message模式
最简单实用的分工方法： 为每个任务分配一个对立的线程
在 java 领域不知名，是因为 java 语言里的线程是一个重量级的对象。可以使用 Fiber 
在 go 和 lua 语言里的协程，本质上就是一种轻量级的线程。
1. 网络编程里服务端的实现

## Worker Thread模式
避免重复创建线程

